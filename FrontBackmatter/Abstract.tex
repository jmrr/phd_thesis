%*******************************************************
% Abstract
%*******************************************************
%\renewcommand{\abstractname}{Abstract}
\pdfbookmark[1]{Abstract}{Abstract}
\begingroup
\let\clearpage\relax
\let\cleardoublepage\relax
\let\cleardoublepage\relax

\chapter*{Abstract}

Visual localisation and object recognition are key goals of artificial intelligence research that have been traditionally investigated separately. Appearance-based methods can be used to treat both problems from the same perspective. Therefore, the main purpose of this thesis is to explore appearance-based methods in the specific contexts of object recognition and visual localisation from wearable and hand-held devices. Specifically, the contributions of this thesis are as follows:

The first topic of study was the object recognition of grocery products acquired with hand-held and wearable cameras, a use case of particular relevance for the blind and partially sighted. The main contributions around this topic are a) the SHORT dataset, comprising 100 categories and more than 135,000 images between its training and query sets; and b) an open-source pipeline and complete evaluation of popular bag-of-visual-words (BoVW) techniques when tested against SHORT. The SHORT dataset is novel as it introduces a clear distinction between high quality training images and query images taken in the wild. This is an anticipated scenario in which retailers would acquire images for their online shopping brochures and users would submit their own images for recognition with varying quality. The performance results of the methods tested demonstrate the challenging characteristics of SHORT.

The second object of study was indoor localisation from hand-held and wearable cameras. For this topic, the RSM dataset was constructed, containing more than 130,000 images along more than 3 km of indoor journeys. An open-source pipeline and evaluation is also contributed in this area. The methods include a selection of custom-created single-frame and spatio-temporal image descriptors methods. These are tested against baseline appearance-based methods such as SIFT and HOG3D and state-of-the-art SLAM. Results show that appearance-based methods, even in the absence of tracking, can provide enough information to infer location with error as small as 1.5 m over a 50 m journey. Within these appearance-based methods, results suggest that single-frame methods perform slightly better than spatio-temporal approaches.

In third place, we have developed a model of the biological place cells, the artificial place cells based on kernel distance metrics of appearance-based methods between query and database images. We also tested their performance under the challenging conditions of indoor localisation, achieving errors as low as 1.4 m in a 50 m and comparing favourably with the state of the art SLAM. 

Finally, we have prototyped an assistive localisation system using wearable or hand-held visual input and tactile feedback to track the localisation of the user over haptic maps.


\vfill

%\pdfbookmark[1]{Resumen}{Resumen}
%\chapter*{Resumen}
%Abstract in Spanish\dots


\endgroup			

\vfill