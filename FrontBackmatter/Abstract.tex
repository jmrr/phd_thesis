%*******************************************************
% Abstract
%*******************************************************
%\renewcommand{\abstractname}{Abstract}
\pdfbookmark[1]{Abstract}{Abstract}
\begingroup
\let\clearpage\relax
\let\cleardoublepage\relax
\let\cleardoublepage\relax

\chapter*{Abstract}

Visual localisation and object recognition are key goals of artificial intelligence research that have been traditionally investigated separately. Appearance-based methods can be used to treat both problems from the same perspective. Therefore, the main purpose of this thesis is to explore appearance-based methods in the specific contexts of wearable and hand-held object recognition and visual localisation. Specifically, the contributions of this thesis is as follows:

In first place, we have constructed the SHORT and RSM datasets for hand-held and wearable object recognition and indoor visual localisation, respectively. SHORT contains 100 categories and more than 135,000 images, and the RSM dataset contains, in the December 2015 version, more than 150,000 images of indoor journeys along more than 3 km. We have also studied the constraints of the data problem in the cases of object recognition and indoor visual localisation when the visual input (images or video) are acquired by wearable or hand-held devices, defining two evaluation benchmarks, and a novel metric based on the probability of localisation error. 

In second place, using these datasets and those provided by the community, we constructed evaluation pipelines for object recognition and visual localisation; and benchmarked custom-created image desription methods with baseline and state-of-the-art ones for performance in this context. 

In third, place, we have developed a model of the biologicall place cells, the artificial place cells based on kernel distance metrics of appearance-based methods between query and database images. We also tested their performance under the challenging conditions of indoor localisation, resulting in a successful compared with the state of the art SLAM. 

Finally, we have prototyped an assistive localisation system using wearable or hand-held visual input and tactile feedback to track the localisation of the user over haptic maps.


\vfill

%\pdfbookmark[1]{Resumen}{Resumen}
%\chapter*{Resumen}
%Abstract in Spanish\dots


\endgroup			

\vfill