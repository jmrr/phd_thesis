@article{CC01a,
annote = {Software available at $\backslash$url\{http://www.csie.ntu.edu.tw/\~{}cjlin/libsvm\}},
author = {Chang, Chih-Chung and Lin, Chih-Jen},
journal = {ACM Transactions on Intelligent Systems and Technology},
number = {3},
pages = {27:1----27:27},
title = {{\{LIBSVM\}: A library for support vector machines}},
volume = {2},
year = {2011}
}
@inproceedings{Csurka2004,
author = {Csurka, Gabriella and Dance, C and Fan, Lixin},
booktitle = {Workshop on Statistical Learning in Computer Vision, ECCV},
pages = {1--22},
title = {{Visual categorization with bags of keypoints}},
url = {http://217.109.185.161/layout/set/print/content/download/20785/148346/file/2004\_010.pdf},
year = {2004}
}
@article{Durrant-Whyte2006,
annote = {
        From Duplicate 2 ( 
        
          Simultaneous localisation and mapping (SLAM): Part I the essential algorithms
        
         - Durrant-Whyte, H.; Bailey, Tim )

        
        
Used in V\&L net grant application as an introduction to SLAM.

        

      },
author = {Durrant-Whyte, H. and Bailey, Tim},
file = {:home/jmr10/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Durrant-Whyte, Bailey - 2006 - Simultaneous localisation and mapping (SLAM) Part I the essential algorithms.pdf:pdf;:home/jmr10/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Durrant-whyte et al. - 2006 - Simultaneous Localization and Mapping Part I.pdf:pdf},
journal = {Robotics and Automation Magazine},
number = {99},
pages = {80},
publisher = {Citeseer},
title = {{Simultaneous localisation and mapping (SLAM): Part I the essential algorithms}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1638022},
volume = {13},
year = {2006}
}
@article{Everingham2009,
abstract = {The PASCAL Visual Object Classes (VOC) challenge is a benchmark in visual object category recognition and detection, providing the vision and machine learning communities with a standard dataset of images and annotation, and standard evaluation procedures. Organised annually from 2005 to present, the challenge and its associated dataset has become accepted as the benchmark for object detection. This paper describes the dataset and evaluation procedure. We review the state-of-the-art in evaluated methods for both classiﬁcation and detection, analyse whether the methods are statistically different, what they are learning from the images (e.g. the object or its context), and what the methods ﬁnd easy or confuse. The paper concludes with lessons learnt in the three year history of the challenge, and proposes directions for future improvement and extension.},
author = {Everingham, Mark and Gool, Luc and Williams, Christopher K I and Winn, John and Zisserman, Andrew},
doi = {10.1007/s11263-009-0275-4},
issn = {09205691},
journal = {International Journal of Computer Vision},
keywords = {benchmark,database,object recognition},
number = {2},
pages = {303--338},
pmid = {20713396},
publisher = {Citeseer},
title = {{The Pascal Visual Object Classes (VOC) Challenge}},
url = {http://www.springerlink.com/index/10.1007/s11263-009-0275-4},
volume = {88},
year = {2009}
}
@misc{Klein2009,
abstract = {Camera phones are a promising platform for hand-held augmented reality. As their computational resources grow, they are becoming increasingly suitable for visual tracking tasks. At the same time, they still offer considerable challenges: Their cameras offer a narrow field-of-view not best suitable for robust tracking; images are often received at less than 15 Hz; long exposure times result in significant motion blur; and finally, a rolling shutter causes severe smearing effects. This paper describes an attempt to implement a keyframe-based SLAMsystem on a camera phone (specifically, the Apple iPhone 3 G). We describe a series of adaptations to the Parallel Tracking and Mapping system to mitigate the impact of the device's imaging deficiencies. Early results demonstrate a system capable of generating and augmenting small maps, albeit with reduced accuracy and robustness compared to SLAM on a PC.},
author = {Klein, G and Murray, D},
booktitle = {2009 8th IEEE International Symposium on Mixed and Augmented Reality},
doi = {10.1109/ISMAR.2009.5336495},
institution = {Dept. of Eng. Sci., Univ. of Oxford, Oxford, UK},
isbn = {9781424453900},
number = {1},
pages = {83--86},
publisher = {Ieee},
title = {{Parallel Tracking and Mapping on a camera phone}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5336495},
volume = {41},
year = {2009}
}
@inproceedings{Lazebnik2006,
author = {Lazebnik, S. and Schmid, C. and Ponce, J.},
booktitle = {Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2006.68},
file = {:media/Data/PhD\_files/References/Spatial Pyramids
\_cvpr06b.pdf:pdf},
isbn = {0-7695-2597-0},
pages = {2169--2178},
publisher = {Ieee},
title = {{Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1641019 http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1641019},
volume = {2},
year = {2006}
}
@article{Lowe2004,
annote = {SIFT journal
      },
author = {Lowe, DG},
file = {:media/Data/PhD\_files/References/10.1023\_B-VISI.0000029664.99615.94:94},
journal = {International journal of computer vision},
keywords = {2004),SIFT (Lowe},
mendeley-tags = {2004),SIFT (Lowe},
title = {{Distinctive image features from scale-invariant keypoints}},
url = {http://www.springerlink.com/index/H4L02691327PX768.pdf},
year = {2004}
}
@article{Manduchi2012,
abstract = {Computer vision holds great promise for helping persons with blindness or visual impairments (VI) to interpret and explore the visual world. To this end, it is worthwhile to assess the situation critically by understanding the actual needs of the VI population and which of these needs might be addressed by computer vision. This article reviews the types of assistive technology application areas that have already been developed for VI, and the possible roles that computer vision can play in facilitating these applications. We discuss how appropriate user interfaces are designed to translate the output of computer vision algorithms into information that the user can quickly and safely act upon, and how system-level characteristics affect the overall usability of an assistive technology. Finally, we conclude by highlighting a few novel and intriguing areas of application of computer vision to assistive technology.},
author = {Manduchi, Roberto and Coughlan, James},
doi = {10.1145/2063176.2063200},
issn = {00010782},
journal = {Communications of the ACM},
number = {1},
pages = {96--104},
pmid = {22815563},
title = {{(Computer) Vision without Sight.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3398697\&tool=pmcentrez\&rendertype=abstract},
volume = {55},
year = {2012}
}
@article{Pradeep2010,
annote = {Visually impaired, navigation, stereocamera, SLAM,},
author = {Pradeep, Vivek and Medioni, Gerard},
doi = {10.1109/CVPRW.2010.5543579},
file = {:home/jmr10/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pradeep, Medioni - 2010 - Robot vision for the visually impaired.pdf:pdf},
isbn = {978-1-4244-7029-7},
journal = {Computer Vision and},
month = jun,
pages = {15--22},
publisher = {Ieee},
title = {{Robot vision for the visually impaired}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5543579 http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5543579},
year = {2010}
}
@inproceedings{Rivera-Rubio2013a,
address = {London},
author = {Rivera-Rubio, Jose and Idrees, Saad and Alexiou, Ioannis and Bharath, Anil A},
booktitle = {British Machine Vision Association Meetings: Vision in an Increasingly Mobile World},
title = {{The SHORT-30 database. Object recognition in an increasingly mobile world}},
url = {https://sites.google.com/site/thepicturethisprojectnetwork/short-database},
year = {2013}
}
@article{VanDeSande2010,
abstract = {Image category recognition is important to access visual information on the level of objects and scene types. So far, intensity-based descriptors have been widely used for feature extraction at salient points. To increase illumination invariance and discriminative power, color descriptors have been proposed. Because many different descriptors exist, a structured overview is required of color invariant descriptors in the context of image category recognition. Therefore, this paper studies the invariance properties and the distinctiveness of color descriptors (software to compute the color descriptors from this paper is available from http://www.colordescriptors.com) in a structured way. The analytical invariance properties of color descriptors are explored, using a taxonomy based on invariance properties with respect to photometric transformations, and tested experimentally using a data set with known illumination conditions. In addition, the distinctiveness of color descriptors is assessed experimentally using two benchmarks, one from the image domain and one from the video domain. From the theoretical and experimental results, it can be derived that invariance to light intensity changes and light color changes affects category recognition. The results further reveal that, for light intensity shifts, the usefulness of invariance is category-specific. Overall, when choosing a single descriptor and no prior knowledge about the data set and object and scene categories is available, the OpponentSIFT is recommended. Furthermore, a combined set of color descriptors outperforms intensity-based SIFT and improves category recognition by 8 percent on the PASCAL VOC 2007 and by 7 percent on the Mediamill Challenge.},
author = {{Van De Sande}, Koen E A and Gevers, Theo and Snoek, Cees G M},
file = {:media/Data/PhD\_files/References/05204091.pdf:pdf},
institution = {Informatics Institute, University of Amsterdam, Science Park 107, 1098 XG Amsterdam, The Netherlands. ksande@uva.nl},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
number = {9},
pages = {1582--1596},
pmid = {20634554},
publisher = {Ieee},
title = {{Evaluating color descriptors for object and scene recognition.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20634554},
volume = {32},
year = {2010}
}
@misc{Vedaldi2008,
author = {Vedaldi, A and Fulkerson, B},
title = {{VLFeat: An Open and Portable Library of Computer Vision Algorithms}},
url = {http://www.vlfeat.org/},
year = {2008}
}
@inproceedings{Wang2012,
author = {Wang, He and Sen, S and Elgohary, Ahmed and Farid, M and Youssef, M},
booktitle = {MobiSys},
file = {:home/jmr10/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - 2012 - Unsupervised Indoor Localization.pdf:pdf},
isbn = {9781450313018},
publisher = {ACM},
title = {{Unsupervised Indoor Localization}},
url = {http://synrg.ee.duke.edu/papers/unloc.pdf},
year = {2012}
}
@inproceedings{Wang2010,
annote = {In a similar vein than KSVD, except that the codebook entries are constrained to be near to each other - not in real space, but feature space.
      },
author = {Wang, Jinjun and Yang, Jianchao and Yu, Kai and Lv, Fengjun and Huang, Thomas and Gong, Yihong},
booktitle = {2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2010.5540018},
file = {:media/Data/PhD\_files/References/Locality Constrained Linear Coding - CVPR10-LLC.pdf:pdf},
isbn = {978-1-4244-6984-0},
month = jun,
pages = {3360--3367},
publisher = {Ieee},
title = {{Locality-constrained Linear Coding for image classification}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5540018},
year = {2010}
}
@techreport{Worsfold2010,
address = {London},
author = {Worsfold, John and Chandler, Edward},
file = {:home/jmr10/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Worsfold, Chandler - 2010 - Wayfinding project.doc:doc},
institution = {Royal National Institute of Blind People},
publisher = {RNIB},
title = {{Wayfinding project}},
year = {2010}
}
