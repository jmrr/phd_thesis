\chapter{Conclusion and future work}\label{ch:conclusion}

\section{Summary of contributions}

In this thesis we have provided several contributions: First we have analysed the impact of computer vision in mobile and wearable technologies in an assistive context, providing complete studies of appearance-based methods for two key applications, hand-held object recognition of household products and indoor navigation.

Second, we have provided a novel artificial place cell (APC) model for the biological counterparts found in the hippoccampus, and tested it under the same challenging conditions of indoor navigation by using a generalised regression neural network as a training mechanisms for learning a positional ground truth from a database.

Third, we took this previous findings to the next step and develop a prototype client-server Android application for assistive localization from wearable and hand-held devices using their visual input and a haptic feedback tablet to provide tactile cues to the location estimates.

These contributions are accompanied by two important datasets, the SHORT dataset for hand-held object recognition and the RSM dataset of \emph{visual paths}.

As we can see, from the computer vision application development pipeline devised in \ref{fig:cv_dev_pipeline} we have accomplished all the stages.

\section{Concluding remarks}

\section{Future work}

Finally, we will summarise here the future work for each line of work already discussed briefly in each chapter.

\subsection{Datasets}

The SHORT dataset can be expanded with more categories...

The RSM dataset more corridors, different devices, and 2D ground truth.

\subsection{Appearance-based methods for visual localization}

\subsection{Biologically inspired localization methods based on place cell models}

\subsection{Assitive localization apps with visual input and haptic feedback}


